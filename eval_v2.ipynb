{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ecad25-9076-4105-bff6-45730e3a21c3",
   "metadata": {},
   "source": [
    "### This script is to evaluate finetuned Llama-3.2-1B with LM head using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b1dbe2-d479-4430-96f9-2568aa19b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% import packages\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88b9117-e837-4127-bffe-b3a59b585ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b82273-6e34-4619-9643-6b6213cbfc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048, padding_idx=128001)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Loading the model and tokenizer\n",
    "\n",
    "model_path = \"./llama3_2_1b_1101_3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
    "                                                           num_labels=2,\n",
    "                                                           torch_dtype=torch.bfloat16,                                                            \n",
    "                                                           low_cpu_mem_usage=True)\n",
    "\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "model.to(device)\n",
    "model.eval() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44150d7-904e-47b6-b25b-d24acea24013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load dataset \n",
    "\n",
    "class RelevanceDataset(Dataset):\n",
    "    def __init__(self, tokenizer, file_path):\n",
    "        self.data = self.load_data(file_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "       \n",
    "        self.cutoffdoc = 300\n",
    "        self.system_prompt = \"\"\" Given the following QUESTION and DOCUMENTS, \n",
    "                            Please analyze the contents of DOCUMENTS and determine \n",
    "                            whether it is relevant in answering the QUESTION. \n",
    "                                \n",
    "                            The output should strictly use the following template: \n",
    "                            Output: \"PASS\" if the contents of DOCUMENTS is relevant in answering the QUESTION\n",
    "                            and \"FAIL\" if the contents is not relevant in answering the QUESTIONâ€™ on the last line.\n",
    "                            \"\"\"\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        data = pd.read_csv(file_path)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.data['question'][idx]\n",
    "        context = self.data['text'][idx]\n",
    "        output = self.data['output'][idx]\n",
    "        shorttext = ' '.join(context.split()[:self.cutoffdoc])\n",
    "        user_prompt = \"\"\"\n",
    "                    QUESTION: {},\n",
    "                    \n",
    "                    DOCUMENTS: {}\n",
    "\n",
    "                    \"\"\".format(question, shorttext)    \n",
    "        # response = \"Output:\" + rec['relevance']    \n",
    "        text = [\"role:\", \"system\",'\\n'  \n",
    "               \"content:\", self.system_prompt,'\\n'\n",
    "               \"role:\", \"user\", '\\n' \n",
    "               \"content\", user_prompt\n",
    "               ]\n",
    "        texts = \" \".join(text)   \n",
    "        \n",
    "        inputs = tokenizer(texts, padding='max_length', max_length=512,truncation=True,return_tensors='pt')\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        #labels = copy.deepcopy(input_ids)\n",
    "        attention_mask = inputs['attention_mask'].squeeze() \n",
    "        return input_ids, attention_mask, output\n",
    "    \n",
    "\n",
    "test_dataset = RelevanceDataset(tokenizer,\"./data/relevance_test3a.csv\" )\n",
    "  \n",
    "\n",
    "batchsize = 40\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batchsize, pin_memory=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2bab56-1609-45e8-92f6-e9e135430bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#%% testing\n",
    "\n",
    "true = []\n",
    "pred = []\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    # Move batch tensors to the device\n",
    "    input_ids = batch[0].to(device)\n",
    "    attention_mask = batch[1].to(device)\n",
    "    labels = batch[2].to(device)\n",
    "    true.append(labels.cpu().tolist())\n",
    "\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        pred.append(predictions.cpu().tolist())  \n",
    "\n",
    "    if i % 10 ==0:\n",
    "        print(i) \n",
    "    if i ==20:  # comment this to evaluate all dataset\n",
    "        break\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6da2d1-38f3-45b0-9886-039c7837a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% save the result\n",
    "\n",
    "#data = pd.DataFrame()\n",
    "#data['true'] = true_list\n",
    "#data['pred'] = pred_list\n",
    "#data.to_csv('./data/llama3_2_1b_1101_3_test.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d8145f-ac4f-4518-85f4-0a5ec255e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% upload the tested result\n",
    "df = pd.read_csv(\"./data/llama3_2_1b_1101_3_test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22fa79b7-c3ce-4ab4-bad4-e5f1efd51051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9353333333333333\n",
      "Precision: 0.7749737118822292\n",
      "Recall: 0.6669683257918552\n",
      "F1: 0.7169260700389105\n"
     ]
    }
   ],
   "source": [
    "#%% accuracy(confusion matrix)\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['pred'][i]==1 and df['true'][i]==1:\n",
    "        tp += 1\n",
    "    elif df['pred'][i]==1 and df['true'][i]==0:\n",
    "        fp += 1\n",
    "    elif df['pred'][i]==0 and df['true'][i]==1:\n",
    "        fn += 1\n",
    "    elif df['pred'][i]==0 and df['true'][i]==0:\n",
    "        tn += 1           \n",
    "\n",
    "total = tp+fp+fn+tn\n",
    "accuracy = (tp+tn)/total\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2/(1/precision+1/recall)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fedb6-48cc-466f-ba8c-2b2decbe6b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
